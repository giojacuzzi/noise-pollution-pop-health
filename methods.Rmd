# Methods

This file documents the entire data processing pipeline.

## Prerequisites

First, set the `database_path` global variable to your local database path.

```{r}
source('global.R')
database_path = '~/../../Volumes/SAFS Work/PHI'

stopifnot(dir.exists(database_path))
```

## Acoustic field monitoring analyses

```{r}
# 0. Retrieve site location information ----------------
sites = st_as_sf(get_data_sites(),
                 coords = c('Longitude', 'Latitude'), 
                 crs = crs, agr = 'constant')
sites = na.omit(sites)
sites = sites[sites$ID %in% unique(get_data_metrics()[,'ID']), ]
sites$Longitude = st_coordinates(sites$geometry)[,'X']
sites$Latitude  = st_coordinates(sites$geometry)[,'Y']
mapview(sites)

# 1. Create tables mapping org files to sites and dates ------------------------
# input: PHI database, 'data/sites.csv'
# outputs: 'data/load/_output/file_map_[ORG].csv'
source('data/load/load_file_jgl.R')
file_map_jgl = map_files_jgl_csv()
source('data/load/load_file_navy.R')
file_map_navy = map_files_navy_csv()
source('data/load/load_file_sda.R')
file_map_sda = map_files_sda_csv()
source('data/load/load_file_nps.R')
file_map_nps = map_files_nps_csv()
file_map = get_file_map() # requires all file_map .csv files

# 2. Load SPL data for each site date ------------------------------------------
# inputs: PHI database, 'file_map_[ORG].csv'
# outputs: '[database_path]/converted/site_dates/[ORG]/[ID]_[DATE].csv'
source('data/load/load_site_date.R')
create_site_date_csvs('JGL')
create_site_date_csvs('NAVY')
create_site_date_csvs('SDA')
create_site_date_csvs('NPS')

# 3. Find noise events for each site date --------------------------------------
# inputs: '[database_path]/converted/site_dates/[ORG]/[ID]_[DATE].csv'
# outputs: 'data/events/_output/events_[ORG].csv'
source('data/analysis/characterization/preprocessing/evaluate_events.R')
calculate_events_csv('JGL')
calculate_events_csv('NAVY')
calculate_events_csv('SDA')
calculate_events_csv('NPS')
# 3.5. Get noise events reported by Navy
# inputs: PHI database
# outputs: 'data/events/_output/navy_reported_events.csv'
source('data/events/load_events_navy.R')

# 4. Calculate metrics for each site date --------------------------------------
# source('analysis/calculate_metrics.R')
# Produce 'data/metrics/metrics.csv'
# calculate_site_date_metrics_csv()

# 6. Calculate OSHA/NIOSH TWA for each site date -------------------------------

#.....
```

## Population Exposure

### Noise simulation modeling with Noisemap

1.  Download "[V. Noise Modeling Data - PUBLIC_NOISEMAP](https://www.navfac.navy.mil/Portals/68/Documents/Business-Lines/Asset-Management/Sound/Remaining-Adds/PUBLIC_NOISEMAP.zip?ver=KEbUPIKWwvnjZl0H4vUg9g%3d%3d)" from NAVY database and unzip.
2.  Format flight operations
    1.  Input: NOISEMAP/NASWI/MP[N]/\*Flight Operations.xml, where 'N' is the monitoring period, 1-4
    2.  Output: .csv for each Flight Operations.xml file, located under 'data/simulation/flight_ops'
    3.  For each Flight Operations.xml file, open in Microsoft Excel. If prompted, do not update workbook links. Then, select File \> Save As \> Comma Separated Values (.csv), and save to the corresponding directory in 'data/simulation/flight_ops/MP[N]'
3.  Run `data/simulation/flight_ops/aggregate_flight_ops.R` to generate the per-period aggregates and the total combined average .csv outputs, respectively.
    1.  Input: 'data/simulation/flight_ops/\*.csv'

    2.  Outputs: 'data/simulation/flight_ops/\_output/NASWI_MP[N]\_Noisemap - Flight Operations Aggregated.csv', 'data/simulation/flight_ops/\_output/NASWI_Noisemap - Flight Operations Combined Average.csv', 'data/simulation/flight_ops/\_output/NASWI_Noisemap - Flight Operations Combined Average - Night Only.csv'; and also simulated adjustments (0.5 and 1.5)

```{r}
source('data/simulation/aggregate_flight_ops.R')
```

4.  Next, open the 'data/simulation/\_output/csv/\* Combined Average \*.csv' files with Microsoft Excel and re-save as .xml files in data/simulation/\_output/xml.
5.  Open 'simulation/DNL/NASWI_Combined_Average_DNL.baseops' with BaseOps. To import new flight operations into BaseOps:
    1.  File \> Import Flight Operations from Spreadsheet
        1.  Option Categories \> File \> Import operations from the following spreadsheet file: \<the xml file you just saved, either the total combined average for DNL and LEQ24, or the "Night Only" for LNIGHT\>
        2.  Option Categories \> Columns:
            1.  Flight Profile Name Column: B (2)
            2.  Num Day Ops Column: H (8)
            3.  Num Night Ops Column: I (9)
        3.  Also import flight tracks: yes
            1.  Flight Track Name Column: C (3)
        4.  Option Categories \> Missing Data
            1.  If a flight profile in the spreadsheet is missing from the BaseOps case, then... Add the missing profile to the BaseOps case
            2.  If a flight profile in the BaseOps case is missing from the spreadsheet, then... Leave the profile unchanged in the BaseOps case
            3.  If you are also importing flight tracks, and a flight track in the spreadsheet is missing from the BaseOps case, then... Set the profile's flight track to "undefined"
        5.  Press OK... You should see the following message: `Importing flight profiles from spreadsheet file NASWI_MP1_Noisemap - Flight Operations.xml.  The following flight profiles appear in both the BaseOps case and the spreadsheet file.  The daily flight profile operation counts in the BaseOps case will be updated to match the values in the spreadsheet file.`

### Run BaseOps simulations and generate NMPlot noise contour maps

*See NoiseMap and AEDT Gap Analysis Technical Report for further details of NoiseMap and BaseOps software. NoiseMap BaseOps cases have been made for DNL and Leq24 (cumulative, see 4.1.1.1) and Lnight (9hr, see 4.1.1.2).*

1.  For a given .baseops file under 'simulation/baseops' (DNL, LEQ24, or LNIGHT), open it with BaseOps, then select `Case > Run Case`
2.  After the case has finished running, select `Case > Plot`. This will open the default contours in NMPlot.
3.  Click the `Edit Options` button. From `Option Categories > Contours > Levels`, manually specify contour levels with a lowest primary level (such as 35) and highest 150, with spacing between primary levels of 1, and 0 secondary levels. Click `Apply`.
    1.  NOTE: To view the contours on a map, you can select Background \> Layers \> Add Layer (SlippyMap) \> Options Title Server - URL Prefix: tile.openstreetmap.org Attribution Text: OpenStreetMap
4.  Select `File > Export to GIS`. Under format, select `ESRI ARC/INFO Shapefile (SHP)`, then click `Properties`
    1.  Coordinate System \> Export in the following coordinate system... WGS 84
    2.  Level of Detail \> Export with a level of detail appropriate for display at a scale of...
        -   1:24000
        -   1 inch = 2000 feet
    3.  Create based upon the filename '....\\simulation\\\_output\\DNL\\DNL' , replacing 'DNL' with the corresponding metric.
5.  Click `OK`

### Validate simulation against measurements from the field

```{r}
source('simulation/validation.R')
```

### Dasymetric population exposure

Generate a dasymetric population density map for all exposed areas.

```{r}
source('simulation/contours.R')

exposed_areas = get_exposed_counties_and_native_lands()

source('analysis/preprocessing/dasymetric.R')
for (id in exposed_areas$counties) generate_dasypop_county(id)
for (id in exposed_areas$native_lands) generate_dasypop_native_land(id)
```

Combine the dasymetric population density maps with the noise contour maps to yield noise exposure across the population.

```{r}
source('analysis/preprocessing/pop_exposure.R')

generate_pop_exposure_stack()
```

Next, conduct health assessment for chosen metrics across the population.

```{r}
source('analysis/health_assessment_summary.R')
```

Conduct childhood learning school impact evaluation.

```{r}
source('analysis/health_wellbeing_impacts/childhood_learning.R')
```
